"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
"""

import asyncio
from aiogram.types import Message, CallbackQuery, InlineKeyboardMarkup
from aiogram.fsm.context import FSMContext
from loguru import logger
import re

from bot.states import ParseStates
from bot.keyboards import get_parse_keyboard, get_staff_item_keyboard, get_confirmation_keyboard
from parser.main import UniversityParser
from database.operations import save_parsing_result, get_user_settings


async def parse_handler(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /parse"""
    user = message.from_user
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ URL –≤ –∫–æ–º–∞–Ω–¥–µ
    command_parts = message.text.split()
    if len(command_parts) > 1:
        url = command_parts[1]
        await parse_url_handler(message, state, url)
    else:
        await message.answer(
            "üîç <b>–ü–∞—Ä—Å–∏–Ω–≥ URL</b>\n\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤—É–∑–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.\n\n"
            "<b>–ü—Ä–∏–º–µ—Ä—ã:</b>\n"
            "‚Ä¢ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–∞—Ñ–µ–¥—Ä—ã\n"
            "‚Ä¢ –°–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n"
            "‚Ä¢ –ü–æ–∏—Å–∫–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞\n\n"
            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ URL –≤ —Å–ª–µ–¥—É—é—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏:",
            reply_markup=get_parse_keyboard(),
            parse_mode="HTML"
        )
        await state.set_state(ParseStates.waiting_for_url)


async def parse_url_handler(message: Message, state: FSMContext, url: str = None):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    if not url:
        url = message.text.strip()
    
    user = message.from_user
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
    if not is_valid_url(url):
        await message.answer(
            "‚ùå <b>–ù–µ–≤–µ—Ä–Ω—ã–π URL</b>\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∞–π—Ç –≤—É–∑–∞.\n"
            "URL –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://",
            parse_mode="HTML"
        )
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º robots.txt
    if not await check_robots_txt(url):
        await message.answer(
            "‚ö†Ô∏è <b>–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ</b>\n\n"
            "–°–∞–π—Ç –∑–∞–ø—Ä–µ—â–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –≤ robots.txt.\n"
            "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥?",
            reply_markup=get_confirmation_keyboard("parse_anyway"),
            parse_mode="HTML"
        )
        await state.update_data(url=url)
        await state.set_state(ParseStates.waiting_for_confirmation)
        return
    
    # –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
    await start_parsing(message, state, url)


async def start_parsing(message: Message, state: FSMContext, url: str):
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    user = message.from_user
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    settings = await get_user_settings(user.id)
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
    parsing_msg = await message.answer(
        f"üöÄ <b>–ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥...</b>\n\n"
        f"URL: {url}\n"
        f"‚è± –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: {settings.get('parsing_timeout', 120)} —Å–µ–∫\n"
        f"üîç –ì–ª—É–±–∏–Ω–∞: {settings.get('max_depth', 2)} —É—Ä–æ–≤–Ω–µ–π\n"
        f"üåê JS —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥: {'–í–∫–ª—é—á–µ–Ω' if settings.get('js_render', True) else '–û—Ç–∫–ª—é—á–µ–Ω'}\n\n"
        f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...",
        parse_mode="HTML"
    )
    
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        parser = UniversityParser(
            rate_limit_delay=settings.get('rate_limit_delay', 2),
            max_depth=settings.get('max_depth', 2),
            js_render_timeout=settings.get('js_render_timeout', 30),
            parsing_timeout=settings.get('parsing_timeout', 120),
            confidence_threshold=settings.get('confidence_threshold', 0.6)
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        results = await parser.parse_url(url)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        parsing_id = await save_parsing_result(
            user_id=user.id,
            url=url,
            results=results,
            settings=settings
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        await show_parsing_results(parsing_msg, results, parsing_id)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user.id}: {e}")
        await parsing_msg.edit_text(
            f"‚ùå <b>–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ URL: {url}\n\n"
            f"<b>–û—à–∏–±–∫–∞:</b> {str(e)}\n\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π URL –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.",
            parse_mode="HTML"
        )
    
    finally:
        await state.clear()


async def show_parsing_results(message: Message, results: list, parsing_id: int):
    """–ü–æ–∫–∞–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    if not results:
        await message.edit_text(
            "üîç <b>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞</b>\n\n"
            "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö.\n\n"
            "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
            "‚Ä¢ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö\n"
            "‚Ä¢ –ù–µ–æ–±—Ö–æ–¥–∏–º JS —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–∫–ª—é—á–∏—Ç—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö)\n"
            "‚Ä¢ –°–∞–π—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π URL –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞.",
            parse_mode="HTML"
        )
        return
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ confidence
    high_confidence = [r for r in results if r.get('confidence', 0) >= 0.7]
    medium_confidence = [r for r in results if 0.5 <= r.get('confidence', 0) < 0.7]
    low_confidence = [r for r in results if r.get('confidence', 0) < 0.5]
    
    text = f"‚úÖ <b>–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!</b>\n\n"
    text += f"üìä <b>–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π:</b> {len(results)}\n"
    text += f"‚Ä¢ –í—ã—Å–æ–∫–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {len(high_confidence)}\n"
    text += f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {len(medium_confidence)}\n"
    text += f"‚Ä¢ –ù–∏–∑–∫–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {len(low_confidence)}\n\n"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    for i, result in enumerate(results[:5]):
        text += f"<b>{i+1}. {result.get('fio', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}</b>\n"
        text += f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {result.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n"
        text += f"Email: {result.get('email', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n"
        text += f"–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {result.get('confidence', 0):.2f}\n\n"
    
    if len(results) > 5:
        text += f"... –∏ –µ—â–µ {len(results) - 5} –∑–∞–ø–∏—Å–µ–π\n\n"
    
    text += "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:"
    
    await message.edit_text(
        text,
        parse_mode="HTML",
        reply_markup=get_results_keyboard(parsing_id)
    )


def is_valid_url(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ URL"""
    pattern = re.compile(
        r'^https?://'  # http:// –∏–ª–∏ https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # –¥–æ–º–µ–Ω
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # –ø–æ—Ä—Ç
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return pattern.match(url) is not None


async def check_robots_txt(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt"""
    try:
        import requests
        from urllib.parse import urljoin, urlparse
        
        parsed_url = urlparse(url)
        robots_url = f"{parsed_url.scheme}://{parsed_url.netloc}/robots.txt"
        
        response = requests.get(robots_url, timeout=10)
        if response.status_code == 200:
            robots_content = response.text.lower()
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—Ç –¥–ª—è –≤—Å–µ—Ö –±–æ—Ç–æ–≤
            if "user-agent: *" in robots_content and "disallow: /" in robots_content:
                return False
        
        return True
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å robots.txt: {e}")
        return True  # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Ä–∞–∑—Ä–µ—à–∞–µ–º


def get_results_keyboard(parsing_id: int) -> InlineKeyboardMarkup:
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    builder = InlineKeyboardBuilder()
    
    builder.add(InlineKeyboardButton(
        text="üìã –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ",
        callback_data=f"show_all_{parsing_id}"
    ))
    builder.add(InlineKeyboardButton(
        text="üìÅ –≠–∫—Å–ø–æ—Ä—Ç CSV",
        callback_data=f"export_csv_{parsing_id}"
    ))
    builder.add(InlineKeyboardButton(
        text="üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Ä—É—á–Ω—É—é",
        callback_data=f"manual_check_{parsing_id}"
    ))
    
    builder.adjust(1)
    return builder.as_markup()
